

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>skopt.optimizer.gp &mdash; scikit-optimize 0.7.rc3 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> scikit-optimize
          

          
          </a>

          
            
            
              <div class="version">
                0.7.rc3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../development.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">scikit-optimize</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>skopt.optimizer.gp</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for skopt.optimizer.gp</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Gaussian process-based minimization algorithms.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">base_minimize</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">cook_estimator</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">normalize_dimensions</span>


<div class="viewcode-block" id="gp_minimize"><a class="viewcode-back" href="../../../reference/minimize_functions.html#skopt.gp_minimize">[docs]</a><span class="k">def</span> <span class="nf">gp_minimize</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">base_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">n_calls</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_random_starts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">acq_func</span><span class="o">=</span><span class="s2">&quot;gp_hedge&quot;</span><span class="p">,</span> <span class="n">acq_optimizer</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">n_points</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">model_queue_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bayesian optimization using Gaussian Processes.</span>

<span class="sd">    If every function evaluation is expensive, for instance</span>
<span class="sd">    when the parameters are the hyperparameters of a neural network</span>
<span class="sd">    and the function evaluation is the mean cross-validation score across</span>
<span class="sd">    ten folds, optimizing the hyperparameters by standard optimization</span>
<span class="sd">    routines would take for ever!</span>

<span class="sd">    The idea is to approximate the function using a Gaussian process.</span>
<span class="sd">    In other words the function values are assumed to follow a multivariate</span>
<span class="sd">    gaussian. The covariance of the function values are given by a</span>
<span class="sd">    GP kernel between the parameters. Then a smart choice to choose the</span>
<span class="sd">    next parameter to evaluate can be made by the acquisition function</span>
<span class="sd">    over the Gaussian prior which is much quicker to evaluate.</span>

<span class="sd">    The total number of evaluations, `n_calls`, are performed like the</span>
<span class="sd">    following. If `x0` is provided but not `y0`, then the elements of `x0`</span>
<span class="sd">    are first evaluated, followed by `n_random_starts` evaluations.</span>
<span class="sd">    Finally, `n_calls - len(x0) - n_random_starts` evaluations are</span>
<span class="sd">    made guided by the surrogate model. If `x0` and `y0` are both</span>
<span class="sd">    provided then `n_random_starts` evaluations are first made then</span>
<span class="sd">    `n_calls - n_random_starts` subsequent evaluations are made</span>
<span class="sd">    guided by the surrogate model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `func` [callable]:</span>
<span class="sd">        Function to minimize. Should take a single list of parameters</span>
<span class="sd">        and return the objective value.</span>
<span class="sd">    </span>
<span class="sd">        If you have a search-space where all dimensions have names,</span>
<span class="sd">        then you can use `skopt.utils.use_named_args` as a decorator</span>
<span class="sd">        on your objective function, in order to call it directly</span>
<span class="sd">        with the named arguments. See `use_named_args` for an example.</span>

<span class="sd">    * `dimensions` [list, shape=(n_dims,)]:</span>
<span class="sd">        List of search space dimensions.</span>
<span class="sd">        Each search dimension can be defined either as</span>

<span class="sd">        - a `(lower_bound, upper_bound)` tuple (for `Real` or `Integer`</span>
<span class="sd">          dimensions),</span>
<span class="sd">        - a `(lower_bound, upper_bound, &quot;prior&quot;)` tuple (for `Real`</span>
<span class="sd">          dimensions),</span>
<span class="sd">        - as a list of categories (for `Categorical` dimensions), or</span>
<span class="sd">        - an instance of a `Dimension` object (`Real`, `Integer` or</span>
<span class="sd">          `Categorical`).</span>

<span class="sd">         NOTE: The upper and lower bounds are inclusive for `Integer`</span>
<span class="sd">         dimensions.</span>

<span class="sd">    * `base_estimator` [a Gaussian process estimator]:</span>
<span class="sd">        The Gaussian process estimator to use for optimization.</span>
<span class="sd">        By default, a Matern kernel is used with the following</span>
<span class="sd">        hyperparameters tuned.</span>
<span class="sd">        - All the length scales of the Matern kernel.</span>
<span class="sd">        - The covariance amplitude that each element is multiplied with.</span>
<span class="sd">        - Noise that is added to the matern kernel. The noise is assumed</span>
<span class="sd">          to be iid gaussian.</span>

<span class="sd">    * `n_calls` [int, default=100]:</span>
<span class="sd">        Number of calls to `func`.</span>

<span class="sd">    * `n_random_starts` [int, default=10]:</span>
<span class="sd">        Number of evaluations of `func` with random points before</span>
<span class="sd">        approximating it with `base_estimator`.</span>

<span class="sd">    * `acq_func` [string, default=`&quot;gp_hedge&quot;`]:</span>
<span class="sd">        Function to minimize over the gaussian prior. Can be either</span>

<span class="sd">        - `&quot;LCB&quot;` for lower confidence bound.</span>
<span class="sd">        - `&quot;EI&quot;` for negative expected improvement.</span>
<span class="sd">        - `&quot;PI&quot;` for negative probability of improvement.</span>
<span class="sd">        - `&quot;gp_hedge&quot;` Probabilistically choose one of the above three</span>
<span class="sd">          acquisition functions at every iteration. The weightage</span>
<span class="sd">          given to these gains can be set by `\eta` through `acq_func_kwargs`.</span>
<span class="sd">            - The gains `g_i` are initialized to zero.</span>
<span class="sd">            - At every iteration,</span>
<span class="sd">                - Each acquisition function is optimised independently to</span>
<span class="sd">                  propose an candidate point `X_i`.</span>
<span class="sd">                - Out of all these candidate points, the next point `X_best` is</span>
<span class="sd">                  chosen by `softmax(\eta g_i)`</span>
<span class="sd">                - After fitting the surrogate model with `(X_best, y_best)`,</span>
<span class="sd">                  the gains are updated such that `g_i -= \mu(X_i)`</span>
<span class="sd">        - `&quot;EIps&quot;` for negated expected improvement per second to take into</span>
<span class="sd">          account the function compute time. Then, the objective function is</span>
<span class="sd">          assumed to return two values, the first being the objective value and</span>
<span class="sd">          the second being the time taken in seconds.</span>
<span class="sd">        - `&quot;PIps&quot;` for negated probability of improvement per second. The</span>
<span class="sd">          return type of the objective function is assumed to be similar to</span>
<span class="sd">          that of `&quot;EIps</span>

<span class="sd">    * `acq_optimizer` [string, `&quot;sampling&quot;` or `&quot;lbfgs&quot;`, default=`&quot;lbfgs&quot;`]:</span>
<span class="sd">        Method to minimize the acquistion function. The fit model</span>
<span class="sd">        is updated with the optimal value obtained by optimizing `acq_func`</span>
<span class="sd">        with `acq_optimizer`.</span>

<span class="sd">        The `acq_func` is computed at `n_points` sampled randomly.</span>

<span class="sd">        - If set to `&quot;auto&quot;`, then `acq_optimizer` is configured on the</span>
<span class="sd">          basis of the space searched over.</span>
<span class="sd">          If the space is Categorical then this is set to be &quot;sampling&quot;`.</span>
<span class="sd">        - If set to `&quot;sampling&quot;`, then the point among these `n_points`</span>
<span class="sd">          where the `acq_func` is minimum is the next candidate minimum.</span>
<span class="sd">        - If set to `&quot;lbfgs&quot;`, then</span>
<span class="sd">              - The `n_restarts_optimizer` no. of points which the acquisition</span>
<span class="sd">                function is least are taken as start points.</span>
<span class="sd">              - `&quot;lbfgs&quot;` is run for 20 iterations with these points as initial</span>
<span class="sd">                points to find local minima.</span>
<span class="sd">              - The optimal of these local minima is used to update the prior.</span>

<span class="sd">    * `x0` [list, list of lists or `None`]:</span>
<span class="sd">        Initial input points.</span>

<span class="sd">        - If it is a list of lists, use it as a list of input points.</span>
<span class="sd">        - If it is a list, use it as a single initial input point.</span>
<span class="sd">        - If it is `None`, no initial input points are used.</span>

<span class="sd">    * `y0` [list, scalar or `None`]</span>
<span class="sd">        Evaluation of initial input points.</span>

<span class="sd">        - If it is a list, then it corresponds to evaluations of the function</span>
<span class="sd">          at each element of `x0` : the i-th element of `y0` corresponds</span>
<span class="sd">          to the function evaluated at the i-th element of `x0`.</span>
<span class="sd">        - If it is a scalar, then it corresponds to the evaluation of the</span>
<span class="sd">          function at `x0`.</span>
<span class="sd">        - If it is None and `x0` is provided, then the function is evaluated</span>
<span class="sd">          at each element of `x0`.</span>

<span class="sd">    * `random_state` [int, RandomState instance, or None (default)]:</span>
<span class="sd">        Set random state to something other than None for reproducible</span>
<span class="sd">        results.</span>

<span class="sd">    * `verbose` [boolean, default=False]:</span>
<span class="sd">        Control the verbosity. It is advised to set the verbosity to True</span>
<span class="sd">        for long optimization runs.</span>

<span class="sd">    * `callback` [callable, list of callables, optional]</span>
<span class="sd">        If callable then `callback(res)` is called after each call to `func`.</span>
<span class="sd">        If list of callables, then each callable in the list is called.</span>

<span class="sd">    * `n_points` [int, default=10000]:</span>
<span class="sd">        Number of points to sample to determine the next &quot;best&quot; point.</span>
<span class="sd">        Useless if acq_optimizer is set to `&quot;lbfgs&quot;`.</span>

<span class="sd">    * `n_restarts_optimizer` [int, default=5]:</span>
<span class="sd">        The number of restarts of the optimizer when `acq_optimizer`</span>
<span class="sd">        is `&quot;lbfgs&quot;`.</span>

<span class="sd">    * `kappa` [float, default=1.96]:</span>
<span class="sd">        Controls how much of the variance in the predicted values should be</span>
<span class="sd">        taken into account. If set to be very high, then we are favouring</span>
<span class="sd">        exploration over exploitation and vice versa.</span>
<span class="sd">        Used when the acquisition is `&quot;LCB&quot;`.</span>

<span class="sd">    * `xi` [float, default=0.01]:</span>
<span class="sd">        Controls how much improvement one wants over the previous best</span>
<span class="sd">        values. Used when the acquisition is either `&quot;EI&quot;` or `&quot;PI&quot;`.</span>

<span class="sd">    * `noise` [float, default=&quot;gaussian&quot;]:</span>
<span class="sd">        - Use noise=&quot;gaussian&quot; if the objective returns noisy observations.</span>
<span class="sd">          The noise of each observation is assumed to be iid with</span>
<span class="sd">          mean zero and a fixed variance.</span>
<span class="sd">        - If the variance is known before-hand, this can be set directly</span>
<span class="sd">          to the variance of the noise.</span>
<span class="sd">        - Set this to a value close to zero (1e-10) if the function is</span>
<span class="sd">          noise-free. Setting to zero might cause stability issues.</span>

<span class="sd">    * `n_jobs` [int, default=1]</span>
<span class="sd">        Number of cores to run in parallel while running the lbfgs</span>
<span class="sd">        optimizations over the acquisition function. Valid only</span>
<span class="sd">        when `acq_optimizer` is set to &quot;lbfgs.&quot;</span>
<span class="sd">        Defaults to 1 core. If `n_jobs=-1`, then number of jobs is set</span>
<span class="sd">        to number of cores.</span>

<span class="sd">    * `model_queue_size` [int or None, default=None]</span>
<span class="sd">        Keeps list of models only as long as the argument given. In the</span>
<span class="sd">        case of None, the list has no capped length.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `res` [`OptimizeResult`, scipy object]:</span>
<span class="sd">        The optimization result returned as a OptimizeResult object.</span>
<span class="sd">        Important attributes are:</span>

<span class="sd">        - `x` [list]: location of the minimum.</span>
<span class="sd">        - `fun` [float]: function value at the minimum.</span>
<span class="sd">        - `models`: surrogate models used for each iteration.</span>
<span class="sd">        - `x_iters` [list of lists]: location of function evaluation for each</span>
<span class="sd">           iteration.</span>
<span class="sd">        - `func_vals` [array]: function value for each iteration.</span>
<span class="sd">        - `space` [Space]: the optimization space.</span>
<span class="sd">        - `specs` [dict]`: the call specifications.</span>
<span class="sd">        - `rng` [RandomState instance]: State of the random state</span>
<span class="sd">           at the end of minimization.</span>

<span class="sd">        For more details related to the OptimizeResult object, refer</span>
<span class="sd">        http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check params</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">space</span> <span class="o">=</span> <span class="n">normalize_dimensions</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">base_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">base_estimator</span> <span class="o">=</span> <span class="n">cook_estimator</span><span class="p">(</span>
            <span class="s2">&quot;GP&quot;</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">),</span>
            <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">base_minimize</span><span class="p">(</span>
        <span class="n">func</span><span class="p">,</span> <span class="n">space</span><span class="p">,</span> <span class="n">base_estimator</span><span class="o">=</span><span class="n">base_estimator</span><span class="p">,</span>
        <span class="n">acq_func</span><span class="o">=</span><span class="n">acq_func</span><span class="p">,</span>
        <span class="n">xi</span><span class="o">=</span><span class="n">xi</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="n">kappa</span><span class="p">,</span> <span class="n">acq_optimizer</span><span class="o">=</span><span class="n">acq_optimizer</span><span class="p">,</span> <span class="n">n_calls</span><span class="o">=</span><span class="n">n_calls</span><span class="p">,</span>
        <span class="n">n_points</span><span class="o">=</span><span class="n">n_points</span><span class="p">,</span> <span class="n">n_random_starts</span><span class="o">=</span><span class="n">n_random_starts</span><span class="p">,</span>
        <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="n">n_restarts_optimizer</span><span class="p">,</span>
        <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="o">=</span><span class="n">y0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">model_queue_size</span><span class="o">=</span><span class="n">model_queue_size</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, The scikit-optimize contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>