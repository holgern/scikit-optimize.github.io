{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Use different base estimators for optimization\n\n\nSigurd Carlen, September 2019.\nReformatted by Holger Nahrstaedt 2020\n\n.. currentmodule:: skopt\n\n\nTo use different base_estimator or create a regressor with different parameters,\nwe can create a regressor object and set it as kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport numpy as np\nnp.random.seed(1234)\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Toy example\n-----------\n\nLet assume the following noisy function $f$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise_level = 0.1\n\n# Our 1D toy problem, this is the function we are trying to\n# minimize\n\ndef objective(x, noise_level=noise_level):\n    return np.sin(5 * x[0]) * (1 - np.tanh(x[0] ** 2))\\\n           + np.random.randn() * noise_level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt import Optimizer\nopt_gp = Optimizer([(-2.0, 2.0)], base_estimator=\"GP\", n_initial_points=5,\n                acq_optimizer=\"sampling\", random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-2, 2, 400).reshape(-1, 1)\nfx = np.array([objective(x_i, noise_level=0.0) for x_i in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt.acquisition import gaussian_ei\n\ndef plot_optimizer(res, next_x, x, fx, n_iter, max_iters=5):\n    x_gp = res.space.transform(x.tolist())\n    gp = res.models[-1]\n    curr_x_iters = res.x_iters\n    curr_func_vals = res.func_vals\n\n    # Plot true function.\n    ax = plt.subplot(max_iters, 2, 2 * n_iter + 1)\n    plt.plot(x, fx, \"r--\", label=\"True (unknown)\")\n    plt.fill(np.concatenate([x, x[::-1]]),\n             np.concatenate([fx - 1.9600 * noise_level,\n                             fx[::-1] + 1.9600 * noise_level]),\n             alpha=.2, fc=\"r\", ec=\"None\")\n    if n_iter < max_iters - 1:\n        ax.get_xaxis().set_ticklabels([])\n    # Plot GP(x) + contours\n    y_pred, sigma = gp.predict(x_gp, return_std=True)\n    plt.plot(x, y_pred, \"g--\", label=r\"$\\mu_{GP}(x)$\")\n    plt.fill(np.concatenate([x, x[::-1]]),\n             np.concatenate([y_pred - 1.9600 * sigma,\n                             (y_pred + 1.9600 * sigma)[::-1]]),\n             alpha=.2, fc=\"g\", ec=\"None\")\n\n    # Plot sampled points\n    plt.plot(curr_x_iters, curr_func_vals,\n             \"r.\", markersize=8, label=\"Observations\")\n    plt.title(r\"x* = %.4f, f(x*) = %.4f\" % (res.x[0], res.fun))\n    # Adjust plot layout\n    plt.grid()\n\n    if n_iter == 0:\n        plt.legend(loc=\"best\", prop={'size': 6}, numpoints=1)\n\n    if n_iter != 4:\n        plt.tick_params(axis='x', which='both', bottom='off',\n                        top='off', labelbottom='off')\n\n    # Plot EI(x)\n    ax = plt.subplot(max_iters, 2, 2 * n_iter + 2)\n    acq = gaussian_ei(x_gp, gp, y_opt=np.min(curr_func_vals))\n    plt.plot(x, acq, \"b\", label=\"EI(x)\")\n    plt.fill_between(x.ravel(), -2.0, acq.ravel(), alpha=0.3, color='blue')\n\n    if n_iter < max_iters - 1:\n        ax.get_xaxis().set_ticklabels([])\n\n    next_acq = gaussian_ei(res.space.transform([next_x]), gp,\n                           y_opt=np.min(curr_func_vals))\n    plt.plot(next_x, next_acq, \"bo\", markersize=6, label=\"Next query point\")\n\n    # Adjust plot layout\n    plt.ylim(0, 0.07)\n    plt.grid()\n    if n_iter == 0:\n        plt.legend(loc=\"best\", prop={'size': 6}, numpoints=1)\n\n    if n_iter != 4:\n        plt.tick_params(axis='x', which='both', bottom='off',\n                        top='off', labelbottom='off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GP kernel\n---------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nfig.suptitle(\"Standard GP kernel\")\nfor i in range(10):\n    next_x = opt_gp.ask()\n    f_val = objective(next_x)\n    res = opt_gp.tell(next_x, f_val)\n    if i >= 5:\n        plot_optimizer(res, opt_gp._next_x, x, fx, n_iter=i-5, max_iters=5)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test different kernels\n----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt.learning import GaussianProcessRegressor\nfrom skopt.learning.gaussian_process.kernels import ConstantKernel, Matern\n# Gaussian process with Mat\u00e9rn kernel as surrogate model\n\nfrom sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic,\n                                              ExpSineSquared, DotProduct,\n                                              ConstantKernel)\n\n\nkernels = [1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n           1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1),\n           1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0,\n                                length_scale_bounds=(0.1, 10.0),\n                                periodicity_bounds=(1.0, 10.0)),\n           ConstantKernel(0.1, (0.01, 10.0))\n               * (DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)) ** 2),\n           1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0),\n                        nu=2.5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for kernel in kernels:\n    gpr = GaussianProcessRegressor(kernel=kernel, alpha=noise_level ** 2,\n                                   normalize_y=True, noise=\"gaussian\",\n                                   n_restarts_optimizer=2\n                                   )\n    opt = Optimizer([(-2.0, 2.0)], base_estimator=gpr, n_initial_points=5,\n                    acq_optimizer=\"sampling\", random_state=42)\n    fig = plt.figure()\n    fig.suptitle(repr(kernel))\n    for i in range(10):\n        next_x = opt.ask()\n        f_val = objective(next_x)\n        res = opt.tell(next_x, f_val)\n        if i >= 5:\n            plot_optimizer(res, opt._next_x, x, fx, n_iter=i - 5, max_iters=5)\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}